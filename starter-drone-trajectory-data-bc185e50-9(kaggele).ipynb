{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "1.4.7\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) \n",
    "import keras_tuner as kt\n",
    "print(kt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 276 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# 06162020_111957.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df1 = pd.read_csv('FLY009.csv', delimiter=',', nrows = nRowsRead)\n",
    "df1.dataframeName = 'p.csv'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date_float  time_float\n",
      "0           NaN         NaN\n",
      "1       17381.0    0.756042\n",
      "2       17381.0    0.756042\n",
      "3       17381.0    0.756042\n",
      "4       17381.0    0.756042\n",
      "..          ...         ...\n",
      "995     17381.0    0.756435\n",
      "996     17381.0    0.756435\n",
      "997     17381.0    0.756435\n",
      "998     17381.0    0.756435\n",
      "999     17381.0    0.756435\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the column is already converted to datetime\n",
    "df1['GPS:dateTimeStamp'] = pd.to_datetime(df1['GPS:dateTimeStamp'], errors='coerce')\n",
    "\n",
    "# Strip any timezone information to make sure the datetime is timezone-naive\n",
    "df1['GPS:dateTimeStamp'] = df1['GPS:dateTimeStamp'].dt.tz_localize(None)\n",
    "\n",
    "# Define the reference date as timezone-naive (1970-01-01)\n",
    "reference_date = pd.Timestamp('1970-01-01')\n",
    "\n",
    "# Convert date to float (days since the reference date)\n",
    "df1['date_float'] = (df1['GPS:dateTimeStamp'] - reference_date).dt.days\n",
    "\n",
    "# Convert time to float (fraction of a day, based on seconds since midnight)\n",
    "df1['time_float'] = (\n",
    "    df1['GPS:dateTimeStamp'].dt.hour * 3600 + \n",
    "    df1['GPS:dateTimeStamp'].dt.minute * 60 + \n",
    "    df1['GPS:dateTimeStamp'].dt.second\n",
    ") / 86400  # 86400 seconds in a day\n",
    "\n",
    "# Display the updated DataFrame with float values for date and time\n",
    "print(df1[['date_float', 'time_float']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 278 entries, Clock:Tick# to time_float\n",
      "dtypes: datetime64[ns](1), float64(258), int64(1), object(18)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop('GPS:dateTimeStamp',axis=1)  # axis=1 indicates dropping a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 277 entries, Clock:Tick# to time_float\n",
      "dtypes: float64(258), int64(1), object(18)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15109\n"
     ]
    }
   ],
   "source": [
    "#pip install missingno\n",
    "n=df1.isnull().sum().sum()\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "# Visualize missing data\n",
    "msno.matrix(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in each column\n",
    "missing_data = df1.isnull().sum()\n",
    "\n",
    "# Display columns with missing values and their count\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values in each column\n",
    "missing_percentage = (df1.isnull().sum() / len(df1)) * 100\n",
    "print(missing_percentage[missing_percentage == 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 277 entries, Clock:Tick# to time_float\n",
      "dtypes: float64(258), int64(1), object(18)\n",
      "memory usage: 2.1+ MB\n",
      "15109\n"
     ]
    }
   ],
   "source": [
    "df1.info()\n",
    "n=df1.isnull().sum().sum()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 263 entries, Clock:Tick# to time_float\n",
      "dtypes: float64(247), int64(1), object(15)\n",
      "memory usage: 2.0+ MB\n",
      "1187\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "threshold = 0.5  # 50%\n",
    "df1 = df1.loc[:, df1.isnull().mean() < threshold]\n",
    "df1.info()\n",
    "n=df1.isnull().sum().sum()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 248 entries, Clock:Tick# to time_float\n",
      "dtypes: float64(247), int64(1)\n",
      "memory usage: 1.9 MB\n",
      "1172\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.select_dtypes(exclude=['object'])\n",
    "df1.info()\n",
    "n=df1.isnull().sum().sum()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Forward Fill (ffill):\n",
    "How it works: This method fills missing values with the last known valid value from earlier in the time series.\n",
    "Scenario: When a sensor temporarily stops sending data but is expected to continue the trend or pattern from the last valid reading, forward fill can be appropriate.\n",
    "Use case in drone trajectory:\n",
    "Example: If a GPS signal is lost briefly, it makes sense to use the last known position until new data is received. The drone's trajectory is likely to continue from its last known state unless there is a sudden change in velocity or direction.\n",
    "Advantages: It is a safe assumption in many real-time systems where missing data represents a temporary dropout, and the last known state provides a reasonable approximation.\n",
    "Drawbacks: If there is a rapid change in the trajectory (e.g., a sudden turn or acceleration), forward fill might not capture it, and relying too much on old data can lead to inaccuracies.\n",
    "python\n",
    "Copy code\n",
    "# Forward fill\n",
    "df1.fillna(method='ffill', inplace=True)\n",
    "When to use forward fill:\n",
    "\n",
    "When sensor readings are continuous and missing values represent temporary gaps.\n",
    "When the system is expected to follow the same trend until new data arrives (e.g., in the absence of GPS data, assume the drone continues along the same path).\n",
    "If the missing data is sparse and spread over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Approach: Interpolation\n",
    "In some cases, using interpolation (estimating missing values based on trends between previous and future data points) might give more accurate results than both forward and backward fill:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Linear interpolation to estimate missing values\n",
    "df1.interpolate(method='linear', inplace=True)\n",
    "This can work well if the drone’s motion is expected to follow a smooth trajectory. Interpolation will estimate the missing data points based on nearby values, creating a continuous trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vines\\AppData\\Local\\Temp\\ipykernel_24112\\2826944481.py:2: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df1.interpolate(method='linear', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Linear interpolation to estimate missing values\n",
    "df1.interpolate(method='linear', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 263 entries, Clock:Tick# to time_float\n",
      "dtypes: float64(247), int64(1), object(15)\n",
      "memory usage: 2.0+ MB\n",
      "1187\n"
     ]
    }
   ],
   "source": [
    "df1.info()\n",
    "n=df1.isnull().sum().sum()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=df1.isnull().sum().sum()\n",
    "print(n)\n",
    "import missingno as msno\n",
    "\n",
    "# Visualize missing data\n",
    "msno.matrix(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df1 is your DataFrame\n",
    "\n",
    "# Select all string (object) columns\n",
    "string_columns = df1.select_dtypes(include=['object']).columns\n",
    "print(string_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each column to float\n",
    "for col in string_columns:\n",
    "    df1[col] = pd.to_numeric(df1[col], errors='coerce')  # Convert to float, invalid parsing will be set as NaN\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df1.corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For trajectory prediction of a drone using LSTM, your target feature(s) should be the drone's future position. Specifically, the features that represent the drone's location or movement over time are important to predict, such as latitude (lat), longitude (lon), and altitude (alt).\n",
    "\n",
    "Potential Target Features for Trajectory Prediction:\n",
    "lat (Latitude): The geographical latitude of the drone.\n",
    "lon (Longitude): The geographical longitude of the drone.\n",
    "alt (Altitude): The altitude of the drone.\n",
    "In a typical drone trajectory prediction task, you'd aim to predict these features based on the previous time steps.\n",
    "\n",
    "Example Target Feature(s):\n",
    "If you want to predict the next position of the drone in terms of latitude, longitude, and altitude, you would set:\n",
    "Target (y): ['lat', 'lon', 'alt']\n",
    "These would be the dependent variables (targets) you're trying to predict.\n",
    "Model Setup for Multiple Targets:\n",
    "Since you're predicting three target variables (latitude, longitude, and altitude), your LSTM model's output layer should have 3 output units (one for each feature).\n",
    "\n",
    "Example Setup:\n",
    "Input (Features): The features you provided (like x_gyro, y_gyro, z_gyro, pitch, yaw, etc.) will be used as input data to the LSTM model.\n",
    "Input (X) = ['x_gyro', 'y_gyro', 'z_gyro', 'x_acc', 'y_acc', 'z_acc', 'north', 'east', 'down', 'pitch', 'yaw', 'roll', 'wind_speed', 'wind_direction', 'year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "Output (Target): You want to predict the future lat, lon, and alt:\n",
    "Output (y) = ['lat', 'lon', 'alt']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Approach 2: Splitting First, Then Standardizing (Recommended)\n",
    "Here’s why this is generally preferred: By splitting first, you avoid data leakage, where information from the test set could influence the training process. \n",
    "It’s better to ensure that the scaling parameters (like mean and standard deviation) are derived only from the training set and then applied to the test set.\n",
    "Explanation of the Steps:\n",
    "Split your dataset first using train_test_split().\n",
    "Fit the StandardScaler on X_train to compute the mean and standard deviation based only on the training data.\n",
    "Transform both X_train and X_test using the same scaler object:\n",
    "fit_transform(X_train) to compute the parameters and scale X_train.\n",
    "transform(X_test) to apply the scaling without recomputing the parameters, ensuring no leakage of information from the test set.\n",
    "Why this is better:\n",
    "Avoids data leakage: The test set is never used during training, so by splitting first and then scaling, you ensure the model doesn't have access to the test set's information during training.\n",
    "Realistic evaluation: You simulate a real-world scenario where the model will not know anything about unseen data before it's scaled or processed.\n",
    "So, to answer your question: yes, you can use train_test_split after standardization, but it's usually better to split first, then standardize the training and test sets separately.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Key Steps for Building and Training an LSTM Model:\n",
    "-Reshape the data for time series input.\n",
    "-Define and build the LSTM model.\n",
    "-Train the model.\n",
    "-Evaluate the model on the test set.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. Data Preparation for LSTM\n",
    "An LSTM model expects the input data to be in 3D format:\n",
    "\n",
    "(samples, timesteps, features), where:\n",
    "-samples is the number of data samples,\n",
    "-timesteps is the number of past time steps to look back for each prediction,\n",
    "-features is the number of features (e.g., latitude, longitude, altitude, etc.).\n",
    "-First, you need to reshape your data into sequences that LSTM can process.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep=['lat', 'lon', 'alt']\n",
    "ind=['x_gyro', 'y_gyro', 'z_gyro', 'x_acc', 'y_acc', 'z_acc', 'north', 'east', 'down', 'pitch', 'yaw', 'roll', 'wind_speed', 'wind_direction', 'year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "y= df1[dep]\n",
    "x=df1[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset first\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler to transform the test set (but don't fit again!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Now X_train_scaled and X_test_scaled are standardized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X_train_scaled : {X_train_scaled .shape}\")\n",
    "print(f\"Shape of X_test_scaled: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize RFE with the model\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)  # Select top 5 features\n",
    "rfe.fit(x, y)  # Make sure to pass DataFrames to RFE\n",
    "\n",
    "# Get selected features\n",
    "selected_features = [ind[i] for i in range(len(ind)) if rfe.support_[i]]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Use selected features for further modeling\n",
    "X_selected = x[selected_features]  # Subset the DataFrame with selected features'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the features you want to scale\n",
    "features_to_scale = [ 'x_gyro', 'y_gyro', 'z_gyro', 'year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler and transform the data\n",
    "X = scaler.fit_transform(x)\n",
    "print(x)\n",
    "# Print the scaled dataframe\n",
    "#print(df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of time steps (look-back window)\n",
    "n_steps = 5 # You can choose the look-back window based on your problem (e.g., 10 previous time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training data into sequences for LSTM\n",
    "def create_sequences(X, y, n_steps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - n_steps):\n",
    "        Xs.append(X[i:i + n_steps].values)  # Get the previous 'n_steps' time steps\n",
    "        ys.append(y.iloc[i + n_steps])  # The corresponding target value\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, n_steps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape of the input data should now be (samples, timesteps, features)\n",
    "print(f\"X_train_seq shape: {X_train_seq.shape}\")\n",
    "print(f\"y_train_seq shape: {y_train_seq.shape}\")\n",
    "print(f\"Shape of X_test_seq: {X_test_seq.shape}\")  # Should be (samples,)\n",
    "print(f\"Shape of y_test_seq: {y_test_seq.shape}\")  # Should be (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of X_test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test set has enough data for sequence creation\n",
    "if len(X_test) > n_steps:\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test, y_test, n_steps)\n",
    "    print(f\"Shape of X_test_seq: {X_test_seq.shape}\")\n",
    "    print(f\"Shape of y_test_seq: {y_test_seq.shape}\")\n",
    "else:\n",
    "    print(\"Not enough test data for sequence creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the LSTM layer with 50 units (neurons) and input shape corresponding to (timesteps, features)\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(n_steps, X_train_seq.shape[2])))\n",
    "\n",
    "# Optionally, add a Dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer (1 unit if predicting one value like future latitude, or multiple units if multivariate output)\n",
    "model.add(Dense(3))  # Replace '1' with the number of outputs if you have more (e.g., 3 for lat, lon, alt)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X_train_seq: {X_train_seq.shape}\")  # Should be (samples, timesteps, features)\n",
    "print(f\"Shape of X_test_seq: {X_test_seq.shape}\")\n",
    "print(f\"Shape of y_test_seq: {y_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())  # To verify the structure\n",
    "print(y_train.head())  # To verify the structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))  # Ensure this is greater than n_steps (e.g., 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model definition\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(n_steps, X_train_seq.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3))  # Output layer for single output (e.g., predicting lat, lon, or alt)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X_test_seq: {X_test_seq.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_test_seq) == 0:\n",
    "    print(\"Test set is empty, cannot make predictions.\")\n",
    "else:\n",
    "    y_pred = model.predict(X_test_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test set has enough data for sequence creation\n",
    "if len(X_test) > n_steps:\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test, y_test, n_steps)\n",
    "    print(f\"Shape of X_test_seq: {X_test_seq.shape}\")\n",
    "    print(f\"Shape of y_test_seq: {y_test_seq.shape}\")\n",
    "else:\n",
    "    print(\"Not enough test data for sequence creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test_seq, y_pred)\n",
    "mae = mean_absolute_error(y_test_seq, y_pred)\n",
    "r2 = r2_score(y_test_seq, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training loss and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32), \n",
    "                   return_sequences=False, \n",
    "                   input_shape=(n_steps, X_train_seq.shape[2])))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Increase to explore more hyperparameter combinations\n",
    "    executions_per_trial=2,  # Average results across multiple runs\n",
    "    directory='tuning',\n",
    "    project_name='lstm_trajectory_v2'\n",
    ")\n",
    "\n",
    "'''tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuning',\n",
    "    project_name='lstm_trajectory'\n",
    ")'''\n",
    "\n",
    "# Start the hyperparameter search\n",
    "tuner.search(X_train_seq, y_train_seq, epochs=20, validation_data=(X_test_seq, y_test_seq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Evaluate the Model on Test Data\n",
    "After tuning, you can retrieve the best model and evaluate it on your test set (X_test_seq, y_test_seq). This will give you a better idea of how well it generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model from the tuning process\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss = best_model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Visualize Predictions\n",
    "Visualizing the predicted trajectories vs. the actual trajectories will give you a clear idea of how well the model is performing. You can plot some of the predictions against the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message IndexError: index 3 is out of bounds for axis 0 with size 3 indicates that your predictions array or y_test_seq contains fewer than 5 samples. Specifically, it looks like there are only 3 samples in predictions (or y_test_seq), so when you're trying to access predictions[3], it's out of bounds.\n",
    "\n",
    "How to Fix It\n",
    "You need to make sure that you're not trying to plot more samples than are available in predictions or y_test_seq. You can modify your code to check the length of predictions or y_test_seq before plotting.\n",
    "\n",
    "Here’s an updated version of your code that will adjust the range of the plot loop dynamically based on the actual size of the predictions array:\n",
    "Explanation:\n",
    "num_samples is calculated as the minimum of the lengths of predictions and y_test_seq, ensuring that you only try to plot as many samples as are available in both arrays.\n",
    "The loop iterates only up to num_samples, which prevents the IndexError from occurring.\n",
    "This should solve the error and plot the available samples without exceeding the bounds of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions using the best model\n",
    "predictions = best_model.predict(X_test_seq)\n",
    "\n",
    "# Determine how many samples are available\n",
    "num_samples = min(len(predictions), len(y_test_seq))\n",
    "\n",
    "# Plot the predicted and actual values for available samples\n",
    "for i in range(num_samples):  # Plot available trajectories\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(predictions[i], label='Predicted')\n",
    "    #plt.plot(y_test_seq[i], label='Actual')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Analyze and Adjust\n",
    "Inspect learning curve: Check the training and validation losses across epochs to see if your model is overfitting (too low training loss but high validation loss) or underfitting (both losses are high)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model from the tuning process\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Since the tuner itself doesn't store the training history, \n",
    "# you can retrain the best model and capture its history.\n",
    "history = best_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the learning curve: Training Loss vs Validation Loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Fine-tune Hyperparameters Further\n",
    "The current tuning process explored a limited range of hyperparameters (e.g., units and dropout). You can further tune the model by:\n",
    "\n",
    "Adding more trials in the RandomSearch process (max_trials=10, for example).\n",
    "Exploring other hyperparameters, like the learning rate of the Adam optimizer, or trying different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Increase to explore more hyperparameter combinations\n",
    "    executions_per_trial=2,  # Average results across multiple runs\n",
    "    directory='tuning',\n",
    "    project_name='lstm_trajectory_v2'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Make Predictions Using the Best Model\n",
    "Once the hyperparameter tuning is complete, you can retrieve the best model and make predictions on your test data (X_test_seq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model from the tuning process\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_model.predict(X_test_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Calculate Accuracy or Performance Metric\n",
    "For trajectory prediction, typical accuracy metrics include Mean Squared Error (MSE) or Mean Absolute Error (MAE) because this is a regression problem, not a classification problem. You can calculate the error between the predicted and actual values.\n",
    "\n",
    "Here’s how to calculate MSE and MAE on your predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_test_seq shape: {y_test_seq.shape}\")\n",
    "print(f\"predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape predictions to match y_test_seq if necessary\n",
    "predictions = np.repeat(predictions, y_test_seq.shape[1], axis=1)  # Assuming repeating is valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_test_seq shape: {y_test_seq.shape}\")\n",
    "print(f\"predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate MSE and MAE\n",
    "mse = mean_squared_error(y_test_seq, predictions)\n",
    "mae = mean_absolute_error(y_test_seq, predictions)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Visualize Path Prediction\n",
    "You can visualize the predicted paths against the actual paths to better understand the performance of your model.\n",
    "predictions[i]: This represents the predicted path for the ith sample from X_test_seq.\n",
    "y_test_seq[i]: This is the actual path corresponding to the ith sample.\n",
    "The visual comparison between the predicted and actual trajectories will give you an idea of how well your LSTM model captures the path dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the number of samples available (use the minimum of predictions and y_test_seq)\n",
    "num_samples = min(len(predictions), len(y_test_seq))\n",
    "\n",
    "# Plot for the available number of samples (max 5 or num_samples)\n",
    "for i in range(min(5, num_samples)):  # Plot for up to 5 trajectories, or fewer if num_samples < 5\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(predictions[i], label='Predicted Path', marker='o')\n",
    "    plt.plot(y_test_seq[i], label='Actual Path', marker='x')\n",
    "    plt.title(f'Trajectory {i+1}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Coordinate Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: (Optional) Save the Model\n",
    "If the results look good and you are satisfied with the performance, you can save the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "\n",
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can later load the saved model using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('best_lstm_trajectory_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Steps:\n",
    "Make predictions on the test data.\n",
    "Calculate MSE and MAE to quantify the prediction error.\n",
    "Visualize the predicted paths against the actual paths.\n",
    "Optionally, save the best model for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
